{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "from pyspark.sql.types import DoubleType, IntegerType, TimestampType, StringType\n",
    "import time\n",
    "\n",
    "# Create a new spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "In This project, A data lake will be preapred for immigration analysis and functionalities. Immigration is an ongoing daily activity, hence data is always increasing. The reason behind choosing a data lake was that they can be accessed and updated easily. \n",
    "<br>\n",
    "The Project will prepare the data model & data lake for Immigration analytics. The notebook is broken into 5 steps\n",
    "1. We will first import the data sets (which as stored as csv/text and sas formats) and explore them defining the cleaning steps required for our data\n",
    "2. Cleaning steps will be performed and data will be verified. \n",
    "3. The definition of immigration data lake's DATA MODEL.\n",
    "4. Definitions and code of data pipeline stages along with full ETL cycle which reads data, cleans it and writes it back as parquet files\n",
    "5. Final write up.\n",
    "\n",
    "At Step 4 the project, we will provide some examples of the analytic reports including:\n",
    "  - Which where the top 5 busiest ports in month 04 / 2016  \n",
    "  - Which months have the highest immigration inflow.\n",
    "  - Which US Port/States have the highest number of immigrants, what is their visa type (i.e. Student, Business, Pleasure)\n",
    "  - Which airline has the maximum number of passengers\n",
    "  - Which residence country has the highest number of students\n",
    "\n",
    "### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included?  \n",
    "\n",
    "5 different data sets are used to prepare the final data model \n",
    "  1. US Cities Demographics - Data set for population and race distribution in each US city.\n",
    "  2. Airline-Codes - A data set with all iata airline codes (Source : https://www.kaggle.com/open-flights/airline-database#airlines.csv) \n",
    "  3. I94 Immigration Data - A detailed data set on Immigration flow in US<br>With I94 Immigration Data, we will also use some additional data sets for correlation. namely:\n",
    "  4. PortCodes.txt : This text file contains the relevant City-State information for the arrival port alphabetic codes mentioned within I94 Immigration data\n",
    "  5. CountryCodes.txt : This text file contains the relevant Country to numeric code relation mentioned within I94 Immigration Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "us_ct_demogr = pd.read_csv(\"us-cities-demographics.csv\",sep=\";\")\n",
    "airline_codes = pd.read_csv(\"airline_codes.csv\")\n",
    "\n",
    "# We will also read in the I94 correlation codes here\n",
    "i94_portcodes = pd.read_csv('PortCodes.txt', sep=\"=\", header=None)\n",
    "i94_countrycodes = pd.read_csv('CountryCodes.txt', sep=\"=\", header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore the amount of data within the I94 Immigration set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file = ../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat, size in MB = 450.125 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat, size in MB = 542.8125 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat, size in MB = 423.75 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat, size in MB = 459.0 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat, size in MB = 683.375 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat, size in MB = 596.5625 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat, size in MB = 500.6875 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat, size in MB = 414.0625 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat, size in MB = 530.5 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat, size in MB = 620.0 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat, size in MB = 373.75 \n",
      "file = ../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat, size in MB = 499.0625 \n"
     ]
    }
   ],
   "source": [
    "# check amount of data files in i94 immigration data\n",
    "path = '../../data/18-83510-I94-Data-2016/'\n",
    "files = [f for f in glob.glob(path + \"**/*\", recursive=True)]\n",
    "for f in files:\n",
    "    statinfo = os.stat(f)\n",
    "    print(\"file = %s, size in MB = %s \" % (f,str(statinfo.st_size/1024/1024)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>We can see that there a lot of files, and the sizes state that the files are large, We will use spark to read in one of files at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using spark session, read in one file\n",
    "immigration_data =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "#### Let us see now how many rows of data each one has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US city demographics = (2891, 12) \n",
      "airline codes = (6162, 8) \n",
      "immigration data = 3096313 \n"
     ]
    }
   ],
   "source": [
    "print(\"US city demographics = %s \" % str(us_ct_demogr.shape))\n",
    "print(\"airline codes = %s \" % str(airline_codes.shape))\n",
    "print(\"immigration data = %s \" % str(immigration_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We will first look at  **US City demographics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "2         Hoover        Alabama        38.5          38040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  \n",
       "2                    2.58         AL               Asian   4759  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_ct_demogr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      False\n",
       "State                     False\n",
       "Median Age                False\n",
       "Male Population            True\n",
       "Female Population          True\n",
       "Total Population          False\n",
       "Number of Veterans         True\n",
       "Foreign-born               True\n",
       "Average Household Size     True\n",
       "State Code                False\n",
       "Race                      False\n",
       "Count                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_ct_demogr.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the data looks neat and in the format desired. \n",
    "<br> The following steps will be required to clean data and bring it to format desired\n",
    "1. For our project purpose, we mainly require the City and state information.  Columns **[MedianAge, Male population, female population, total population, Number of Veterans,Foreign born, Average household size, race, count]** are not important for the project, they will be removed. \n",
    "2. Looking at the Nulls info, the columns we require are OK (City, State, State Code). \n",
    "3. Normalize column names\n",
    "4. Drop any duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now let us explore **Airline codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Alias</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>Callsign</th>\n",
       "      <th>Country</th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>\\N</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Private flight</td>\n",
       "      <td>\\N</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>135 Airways</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GNL</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>United States</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Airline ID            Name Alias IATA ICAO Callsign        Country Active\n",
       "0          -1         Unknown    \\N    -  NaN       \\N             \\N      Y\n",
       "1           1  Private flight    \\N    -  NaN      NaN            NaN      Y\n",
       "2           2     135 Airways    \\N  NaN  GNL  GENERAL  United States      N"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_codes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analytic requirements, the following changes will be required\n",
    "1. Select only rows where iata_code and Country are present\n",
    "2. Remove columns **Alias,ICAO,Callsign,Active**\n",
    "3. Remove any rows where airline ID is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Finally, lets look at our **Immigration data-set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the codes we have imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                             1\n",
       "0     ALC        ALCAN, AK             \n",
       "1     ANC        ANCHORAGE, AK         \n",
       "2     BAR  BAKER AAF - BAKER ISLAND, AK"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_portcodes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify Null values\n",
    "i94_portcodes[i94_portcodes.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **Port Codes** \n",
    " - The second column will be split into port-Name, State-code using \",\" as seperator\n",
    " - Port codes that are non-US are Nan, they will be updated with \"Non-US\" as their state code\n",
    " - Normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1\n",
       "0  582    MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1  236                                        AFGHANISTAN\n",
       "2  101                                            ALBANIA"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_countrycodes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Country Codes** The format is perfect. We will simply normazlie the columns as [countyCode,countryName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=6.0, i94yr=2016.0, i94mon=4.0, i94cit=692.0, i94res=692.0, i94port='XXX', arrdate=20573.0, i94mode=None, i94addr=None, depdate=None, i94bir=37.0, i94visa=2.0, count=1.0, dtadfile=None, visapost=None, occup=None, entdepa='T', entdepd=None, entdepu='U', matflag=None, biryear=1979.0, dtaddto='10282016', gender=None, insnum=None, airline=None, admnum=1897628485.0, fltno=None, visatype='B2'),\n",
       " Row(cicid=7.0, i94yr=2016.0, i94mon=4.0, i94cit=254.0, i94res=276.0, i94port='ATL', arrdate=20551.0, i94mode=1.0, i94addr='AL', depdate=None, i94bir=25.0, i94visa=3.0, count=1.0, dtadfile='20130811', visapost='SEO', occup=None, entdepa='G', entdepd=None, entdepu='Y', matflag=None, biryear=1991.0, dtaddto='D/S', gender='M', insnum=None, airline=None, admnum=3736796330.0, fltno='00296', visatype='F1'),\n",
       " Row(cicid=15.0, i94yr=2016.0, i94mon=4.0, i94cit=101.0, i94res=101.0, i94port='WAS', arrdate=20545.0, i94mode=1.0, i94addr='MI', depdate=20691.0, i94bir=55.0, i94visa=2.0, count=1.0, dtadfile='20160401', visapost=None, occup=None, entdepa='T', entdepd='O', entdepu=None, matflag='M', biryear=1961.0, dtaddto='09302016', gender='M', insnum=None, airline='OS', admnum=666643185.0, fltno='93', visatype='B2')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Columns:** \n",
    "Using the Label descriptions provided with the source of Data we will **keep** the following column labels\n",
    "- I94YR - 4 digit year   : Year of arrival\n",
    "- I94MON - Numeric month : Month of arrival\n",
    "- I94CIT & I94RES : Corresponding source and residence country. \n",
    "- I94PORT : Corresponding port/airport of arrival. \n",
    "- ARRDATE is the Arrival Date in the USA\n",
    "- I94MODE : mode of arrival. There are 4 options 1 = 'Air', 2 = 'Sea', 3 = 'Land', 9 = 'Not reported'\n",
    "- DEPDATE is the Departure Date from the USA\n",
    "- I94BIR - Age of Respondent in Years ( We have the column BIRYEAR )\n",
    "- I94VISA - Visa codes collapsed into three categories: 1 = Business, 2 = Pleasure, 3 = Student\n",
    "- MATFLAG - Match flag - Match of arrival and departure records \n",
    "- GENDER - Non-immigrant sex \n",
    "- AIRLINE - Airline used to arrive in U.S. \n",
    "- FLTNO - Flight number of Airline used to arrive in U.S. \n",
    "- VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S. \n",
    "\n",
    "The rest of the columns will be dropped\n",
    "\n",
    "**Adjusting Format**\n",
    "- The following columns will be changed to integer types. [i94yr, i94mon, i94cit, i94res, arrdate, depdate, i94bir, i94visa]\n",
    "- **i94MODE** will be changed to string and will be replaced with relevant mode values (i.e. Air, Sea, Land, Unknown)\n",
    "- **i94VISA** will be changed to string and will be replaced with relevant visa types (i.e. Business, Pleasure, Student)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## STEP 2 : Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Cities Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cityName</th>\n",
       "      <th>stateName</th>\n",
       "      <th>stateCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cityName      stateName stateCode\n",
       "0  silver spring       Maryland        MD\n",
       "1         quincy  Massachusetts        MA"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns\n",
    "us_ct_demogr.drop(columns=['Median Age','Male Population','Female Population','Total Population','Number of Veterans','Foreign-born','Average Household Size','Race','Count'],inplace=True)\n",
    "\n",
    "# For simplicity in calling columns, we will modify the column names and remove whitespaces and being them to normalized format\n",
    "us_ct_demogr.columns = ['cityName', 'stateName', 'stateCode']\n",
    "\n",
    "# bring the city column to lower state\n",
    "us_ct_demogr['cityName'] = us_ct_demogr['cityName'].str.lower()\n",
    "\n",
    "# Let us drop duplicates\n",
    "us_ct_demogr.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verify format\n",
    "us_ct_demogr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airline Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airlineID</th>\n",
       "      <th>airlineName</th>\n",
       "      <th>airline_iata_code</th>\n",
       "      <th>airlineCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1Time Airline</td>\n",
       "      <td>1T</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>40-Mile Air</td>\n",
       "      <td>Q5</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airlineID    airlineName airline_iata_code airlineCountry\n",
       "3           3  1Time Airline                1T   South Africa\n",
       "10         10    40-Mile Air                Q5  United States"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only rows with iata_code and country\n",
    "airline_codes = airline_codes[pd.notnull(airline_codes['IATA'])]\n",
    "airline_codes = airline_codes[pd.notnull(airline_codes['Country'])]\n",
    "\n",
    "# Select only rows where airline ID is > 0\n",
    "airline_codes = airline_codes[airline_codes['Airline ID'] > 0]\n",
    "\n",
    "# Remove columns\n",
    "airline_codes.drop(columns=['Alias','ICAO','Callsign','Active'],inplace=True)\n",
    "\n",
    "# Rename Columns\n",
    "airline_codes.columns=['airlineID','airlineName','airline_iata_code','airlineCountry']\n",
    "\n",
    "airline_codes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### I94 Immigration Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portCode</th>\n",
       "      <th>portName</th>\n",
       "      <th>stateCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  portCode   portName stateCode\n",
       "0      ALC      ALCAN        AK\n",
       "1      ANC  ANCHORAGE        AK"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PORT CODES\n",
    "# Split and strip columns \n",
    "i94_portcodes['portName'] = i94_portcodes[1].str.split(',').str[0].str.strip()\n",
    "i94_portcodes['stateCode'] = i94_portcodes[1].str.split(',').str[1].str.strip()\n",
    "\n",
    "# Remove white-spaces\n",
    "i94_portcodes[0] = i94_portcodes[0].str.strip()\n",
    "\n",
    "#  Drop and rename columns\n",
    "i94_portcodes.drop(columns=[1],inplace=True)\n",
    "i94_portcodes.columns=['portCode','portName','stateCode']\n",
    "\n",
    "# Append any NAN stateCodes with 'Non-US'\n",
    "i94_portcodes['stateCode'].fillna('Non-US',inplace=True)\n",
    "\n",
    "i94_portcodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryCode</th>\n",
       "      <th>countryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countryCode                                        countryName\n",
       "0          582    MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1          236                                        AFGHANISTAN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## COUNTRY CODES\n",
    "# Rename columns in country codes\n",
    "i94_countrycodes.columns = ['countryCode','countryName']\n",
    "i94_countrycodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- cit: integer (nullable = true)\n",
      " |-- res: integer (nullable = true)\n",
      " |-- portCode: string (nullable = true)\n",
      " |-- arrDate: integer (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- depDate: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visaType: string (nullable = true)\n",
      " |-- matchFlag: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airlineCode: string (nullable = true)\n",
      " |-- flightNumber: string (nullable = true)\n",
      " |-- visaCat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## IMMIGRATION DATA\n",
    "# First we will fix the column types, below function does that\n",
    "def convert_to_int(df, input_column_name):\n",
    "    df = df.withColumn(input_column_name, df[input_column_name].cast(IntegerType()) )\n",
    "    return df\n",
    "\n",
    "# create a list of columns to convert to integer\n",
    "integer_cols = ['i94yr','i94mon','i94cit','i94res', 'arrdate', 'i94mode','depdate', 'i94bir', 'i94visa']\n",
    "# execute the convert function for each column above.\n",
    "for column in integer_cols:\n",
    "    immigration_data = convert_to_int(immigration_data,column)\n",
    "\n",
    "# convert the i94Mode and i94Visa to string\n",
    "immigration_data = immigration_data.withColumn(\"i94mode\", immigration_data[\"i94mode\"].cast( StringType() ) )\n",
    "immigration_data = immigration_data.withColumn(\"i94visa\", immigration_data[\"i94visa\"].cast( StringType() ) )\n",
    "\n",
    "# Replace the mode and visa with its true values\n",
    "i94modes = { '1':'Air', '2':'Sea', '3':'Land', '9':'Not reported' }\n",
    "i94visas = { '1':'Business', '2':'Pleasure', '3':'Student' }\n",
    "\n",
    "immigration_data = immigration_data.replace(to_replace=i94modes, subset=['i94mode'])\n",
    "immigration_data = immigration_data.replace(to_replace=i94visas, subset=['i94visa'])\n",
    "\n",
    "# now we drop all columns that are not required. \n",
    "# create a list of columns to keep\n",
    "select_list = ['i94yr','i94mon','i94cit','i94res','i94port','arrdate','i94mode','depdate','i94bir','i94visa','matflag','gender','airline','fltno','visatype']\n",
    "for column in immigration_data.columns:\n",
    "    if column not in select_list:\n",
    "        immigration_data = immigration_data.drop(column)\n",
    "\n",
    "# Normalize the column names\n",
    "new_names = ['year', 'month','cit','res','portCode','arrDate','mode','depDate','age','visaType','matchFlag','gender','airlineCode','flightNumber','visaCat']\n",
    "immigration_data = immigration_data.toDF(*new_names)\n",
    "\n",
    "# Print the schema to make sure everything is as required\n",
    "immigration_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2016, month=9, cit=213, res=213, portCode='HOU', arrDate=20698, mode='Air', depDate=20725, age=27, visaType='Business', matchFlag='M', gender='M', airlineCode='QK', flightNumber='8111', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=369, res=369, portCode='WAS', arrDate=20698, mode='Air', depDate=20725, age=71, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='KL', flightNumber='651', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='LVG', arrDate=20698, mode='Air', depDate=20702, age=25, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='4O', flightNumber='970', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=691, res=582, portCode='MIA', arrDate=20698, mode='Air', depDate=20702, age=50, visaType='Business', matchFlag='M', gender='M', airlineCode='AM', flightNumber='428', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=266, res=266, portCode='CHI', arrDate=20698, mode='Air', depDate=20714, age=34, visaType='Student', matchFlag='M', gender='F', airlineCode='UA', flightNumber='5959', visaCat='F1'),\n",
       " Row(year=2016, month=9, cit=373, res=373, portCode='SAJ', arrDate=20698, mode='Air', depDate=20708, age=26, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='BB', flightNumber='4543', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=514, res=514, portCode='CLT', arrDate=20698, mode='Air', depDate=20702, age=50, visaType='Business', matchFlag='M', gender='M', airlineCode='AA', flightNumber='880', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=245, res=245, portCode='LOS', arrDate=20698, mode='Air', depDate=20703, age=25, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='AC', flightNumber='550', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='NYC', arrDate=20698, mode='Air', depDate=20702, age=43, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='WS', flightNumber='1210', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='HOU', arrDate=20698, mode='Air', depDate=20710, age=29, visaType='Business', matchFlag='M', gender='M', airlineCode='4O', flightNumber='3986C', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='SNA', arrDate=20698, mode='Air', depDate=20701, age=66, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='4O', flightNumber='2952', visaCat='B2'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='LAR', arrDate=20698, mode='Air', depDate=20709, age=46, visaType='Business', matchFlag='M', gender='M', airlineCode='*GA', flightNumber='XAUWK', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=582, res=582, portCode='LVG', arrDate=20698, mode='Air', depDate=20702, age=28, visaType='Business', matchFlag='M', gender='F', airlineCode='Y4', flightNumber='966', visaCat='B1'),\n",
       " Row(year=2016, month=9, cit=124, res=124, portCode='NEW', arrDate=20698, mode='Air', depDate=None, age=43, visaType='Business', matchFlag=None, gender='M', airlineCode='UA', flightNumber='39', visaCat='E2'),\n",
       " Row(year=2016, month=9, cit=245, res=245, portCode='MIA', arrDate=20698, mode='Air', depDate=20700, age=29, visaType='Pleasure', matchFlag='M', gender='M', airlineCode='AM', flightNumber='428', visaCat='B2')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Step 3: Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model.\n",
    "Our source data is now in the required format, below is the column summary<br>\n",
    "**Data Sources**\n",
    "1. City-Demographics : cityName, stateName, stateCode\n",
    "2. i94_portCodes     : portCode, portName, stateCode\n",
    "3. airline_codes     : airlineID, airlineName,airline_iata_code,airlineCountry\n",
    "5. i94_countryCodes  : countryCode, countryName\n",
    "6. immigration_data  : year,month,cit,res,portCode,arrDate,mode,depDate,age,visaCat,matchflag,gender,airlineCode,flightNumber,visatype\n",
    "\n",
    "**FINAL DATA LAKE MODEL**\n",
    "From the cleaned data sets above, we will map the data into our final data lake model as shown in the figure below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/DataModel.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Tables: \n",
    "\n",
    "1. immigration_data : year, month, cit, res, portCode, arrDate, mode, depDate, age, visaType, matchFlag, gender, airlineCode, flightNumber, visaCat\n",
    "2. countryCodes  : countryCode, countryName\n",
    "3. us_state_city : stateCode, stateName, cityName\n",
    "4. us_ports      : portCode, stateCode, portName\n",
    "5. airlineCodes  : airlineID, airlineName, airline_iata_code, airlineCountry\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "There will be two seperate data pipelines for our project\n",
    "\n",
    "- **1st Pipeline : Creating the data model.**\n",
    "    - Read in data from sources\n",
    "    - Clean data \n",
    "    - Create spark data frames from cleaned data\n",
    "    - Write out data frames as parquet files\n",
    "- **2nd Pipeline : Updating immigration data.**\n",
    "    - Read in immigration data\n",
    "    - Clean immigration data \n",
    "    - Read in immigration parquest file into spark data frame\n",
    "    - Update spark data frame with new cleaned data\n",
    "    - Write out data frame as parquest files\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Pipeline common workflows\n",
    "From the pipelines defined : we can combine and reuse the following code for all three pipelines.\n",
    "1. Clean data source\n",
    "2. Write out parquet file\n",
    "\n",
    "Making a common function for both will be useful, as any changes to cleaning / partitioning can be applied directly to these functions without altering the actual pipelines. \n",
    "<br>\n",
    "We will define this code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function we used to convert column types.\n",
    "def convert_to_int(df, input_column_name):\n",
    "    df = df.withColumn(input_column_name, df[input_column_name].cast(IntegerType()) )\n",
    "    return df\n",
    "\n",
    "# Function to clean data sources, code reused from cleaning steps in section 3\n",
    "def clean_data_source(df,sourceName):\n",
    "    \"\"\"\n",
    "        function clean_data_source\n",
    "            input = df :: Type = Spark data frame --> the data frame that requires cleaning\n",
    "                    sourcename :: Type = String --> variable that defines which cleaning steps to take in data. \n",
    "            returns df\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"cleaning {} \".format(sourceName) )\n",
    "        # We seperate cleaning based on sourceName and reuse the code we defined above in cleaning stage\n",
    "        if sourceName == \"immigration_data\":\n",
    "\n",
    "            # create a list of columns to convert to integer\n",
    "            integer_cols = ['i94yr','i94mon','i94cit','i94res', 'arrdate', 'i94mode','depdate', 'i94bir', 'i94visa']\n",
    "            # execute the convert function for each column above.\n",
    "            for column in integer_cols:\n",
    "                df = convert_to_int(df,column)\n",
    "\n",
    "            # convert the i94Mode and i94Visa to string\n",
    "            df = df.withColumn(\"i94mode\", df[\"i94mode\"].cast( StringType() ) )\n",
    "            df = df.withColumn(\"i94visa\", df[\"i94visa\"].cast( StringType() ) )\n",
    "\n",
    "            # Replace the mode and visa with its true values\n",
    "            i94modes = { '1':'Air', '2':'Sea', '3':'Land', '9':'Not reported' }\n",
    "            i94visas = { '1':'Business', '2':'Pleasure', '3':'Student' }\n",
    "\n",
    "            df = df.replace(to_replace=i94modes, subset=['i94mode'])\n",
    "            df = df.replace(to_replace=i94visas, subset=['i94visa'])\n",
    "\n",
    "            # now we drop all columns that are not required. \n",
    "            # create a list of columns to keep\n",
    "            select_list = ['i94yr','i94mon','i94cit','i94res','i94port','arrdate','i94mode','depdate','i94bir','i94visa','matflag','gender','airline','fltno','visatype']\n",
    "            for column in df.columns:\n",
    "                if column not in select_list:\n",
    "                    df = df.drop(column)\n",
    "\n",
    "            # Normalize the column names\n",
    "            new_names = ['year', 'month','cit','res','portCode','arrDate','mode','depDate','age','visaType','matchFlag','gender','airlineCode','flightNumber','visaCat']\n",
    "            df = df.toDF(*new_names)\n",
    "\n",
    "        elif sourceName == \"airlineCodes\":\n",
    "\n",
    "            # Select only rows with iata_code and country\n",
    "            df = df[pd.notnull(df['IATA'])]\n",
    "            df = df[pd.notnull(df['Country'])]\n",
    "\n",
    "            # Select only rows where airline ID is > 0\n",
    "            df = df[df['Airline ID'] > 0]\n",
    "\n",
    "            # Remove columns\n",
    "            df.drop(columns=['Alias','ICAO','Callsign','Active'],inplace=True)\n",
    "\n",
    "            # Rename Columns\n",
    "            df.columns=['airlineID','airlineName','airline_iata_code','airlineCountry']\n",
    "\n",
    "\n",
    "        elif sourceName == \"countryCodes\":\n",
    "\n",
    "            # Rename columns in country codes\n",
    "            df.columns = ['countryCode','countryName']\n",
    "\n",
    "\n",
    "        elif sourceName == \"us_ports\":\n",
    "\n",
    "            # Split and strip columns \n",
    "            df['portName'] = df[1].str.split(',').str[0].str.strip()\n",
    "            df['stateCode'] = df[1].str.split(',').str[1].str.strip()\n",
    "            df[0] = df[0].str.strip()\n",
    "\n",
    "            #  Drop and rename columns\n",
    "            df.drop(columns=[1],inplace=True)\n",
    "            df.columns=['portCode','portName','stateCode']\n",
    "\n",
    "            # Append any NAN stateCodes with 'Non-US'\n",
    "            df['stateCode'].fillna('Non-US',inplace=True)\n",
    "\n",
    "\n",
    "        elif sourceName == \"us_state_cities\":\n",
    "            # Drop the columns\n",
    "            df.drop(columns=['Median Age','Male Population','Female Population','Total Population','Number of Veterans','Foreign-born','Average Household Size','Race','Count'],inplace=True)\n",
    "\n",
    "            # For simplicity in calling columns, we will modify the column names and remove whitespaces and being them to normalized format\n",
    "            df.columns = ['cityName', 'stateName', 'stateCode']\n",
    "\n",
    "            # bring the city column to lower state\n",
    "            df['cityName'] = df['cityName'].str.lower()\n",
    "\n",
    "            # Let us drop duplicates\n",
    "            df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Source Unknown, pipleline not programmed to clean {} \".format(sourceName) )   \n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "    except BaseException as e:\n",
    "        print(\"An exception occurred, invalid data format given for source {} -- ERROR = {} \".format(sourceName,e))\n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "def writeParquet(df, sourceName, output_dest, remove_first):\n",
    "    \"\"\"\n",
    "        function writeParquet\n",
    "            input = df :: Type= Spark Data Frame --> the data frame that requires to be written out to parquet\n",
    "                    sourcename :: Type = String --> variable that defines name of parquet file and also process to write out (e.g. partition by etc). \n",
    "                    output_dest :: destination string to write the parquet file\n",
    "                    remove_first :: Type = Int --> flag indicating whether or not to remove the existing parquet\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #output_dest =\n",
    "        outputfile = output_dest + sourceName + \".parquet\"\n",
    "\n",
    "        # time flag to keep track of how long it takes to write the file. \n",
    "        start = time.time()\n",
    "\n",
    "        #check remove flag\n",
    "        if os.path.exists(outputfile) & remove_first == 1: \n",
    "            print(\"parquet file {} exists, Remove flag is set to 1\".format(outputfile))\n",
    "            shutil.rmtree(outputfile)\n",
    "\n",
    "\n",
    "        if sourceName == \"immigration_data\":\n",
    "            if remove_first==0:\n",
    "                print(\"appending ... \")\n",
    "                df.write.mode(\"append\").partitionBy(\"year\",\"month\").format(\"parquet\").save(outputfile)\n",
    "            else:\n",
    "                df.write.partitionBy(\"year\",\"month\").format(\"parquet\").save(outputfile)\n",
    "\n",
    "        elif sourceName in [\"airlineCodes\",\"countryCodes\",\"us_ports\",\"us_state_cities\"]:\n",
    "            df.write.format(\"parquet\").save(outputfile)\n",
    "\n",
    "        else:\n",
    "            print(\"Source Unknown, pipleline not programmed to write parquet for {} \".format(sourceName) )\n",
    "            sys.exit(1)\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"written out parquet file {} , time taken in seconds = {:.2f} \".format(outputfile,(end - start) ) )\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print(\"Exception occured during writing parquet file -- ERROR = {}\".format(e))\n",
    "        print(\"\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br> \n",
    "\n",
    "### 4.2 1st Pipeline : Create data model\n",
    "Build the data pipelines to create the data model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning us_state_cities \n",
      "cleaning airlineCodes \n",
      "cleaning us_ports \n",
      "cleaning countryCodes \n",
      "cleaning immigration_data \n",
      "parquet file parquet_files/us_state_cities.parquet exists, Remove flag is set to 1\n",
      "written out parquet file parquet_files/us_state_cities.parquet , time taken in seconds = 0.21 \n",
      "parquet file parquet_files/airlineCodes.parquet exists, Remove flag is set to 1\n",
      "written out parquet file parquet_files/airlineCodes.parquet , time taken in seconds = 0.26 \n",
      "parquet file parquet_files/us_ports.parquet exists, Remove flag is set to 1\n",
      "written out parquet file parquet_files/us_ports.parquet , time taken in seconds = 0.21 \n",
      "parquet file parquet_files/countryCodes.parquet exists, Remove flag is set to 1\n",
      "written out parquet file parquet_files/countryCodes.parquet , time taken in seconds = 0.22 \n",
      "parquet file parquet_files/immigration_data.parquet exists, Remove flag is set to 1\n",
      "written out parquet file parquet_files/immigration_data.parquet , time taken in seconds = 53.83 \n"
     ]
    }
   ],
   "source": [
    "# Step 1:  Read in the data here\n",
    "us_ct_demogr = pd.read_csv(\"us-cities-demographics.csv\",sep=\";\")\n",
    "airline_codes = pd.read_csv(\"airline_codes.csv\")\n",
    "i94_portcodes = pd.read_csv('PortCodes.txt', sep=\"=\", header=None)\n",
    "i94_countrycodes = pd.read_csv('CountryCodes.txt', sep=\"=\", header=None)\n",
    "immigration_data =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "\n",
    "\n",
    "# Step 2: Clean Data \n",
    "us_ct_demogr = clean_data_source(us_ct_demogr,\"us_state_cities\")\n",
    "airline_codes = clean_data_source(airline_codes,\"airlineCodes\")\n",
    "i94_portcodes = clean_data_source(i94_portcodes,\"us_ports\")\n",
    "i94_countrycodes = clean_data_source(i94_countrycodes,\"countryCodes\")\n",
    "immigration_data = clean_data_source(immigration_data,\"immigration_data\")\n",
    "\n",
    "\n",
    "# Step 3: Create Spark Data frames from clean data \n",
    "# We do not convert immigration data as it is already a spark data frame\n",
    "us_ct_demogr = spark.createDataFrame(us_ct_demogr)\n",
    "airline_codes = spark.createDataFrame(airline_codes)\n",
    "i94_portcodes = spark.createDataFrame(i94_portcodes)\n",
    "i94_countrycodes = spark.createDataFrame(i94_countrycodes)\n",
    "\n",
    "\n",
    "# Step 4 : Write out data to parquet files\n",
    "writeParquet(us_ct_demogr,\"us_state_cities\",\"parquet_files/\",1)\n",
    "writeParquet(airline_codes,\"airlineCodes\",\"parquet_files/\",1)\n",
    "writeParquet(i94_portcodes,\"us_ports\",\"parquet_files/\",1)\n",
    "writeParquet(i94_countrycodes,\"countryCodes\",\"parquet_files/\",1)\n",
    "writeParquet(immigration_data,\"immigration_data\",\"parquet_files/\",1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2 2nd Pipeline : Updating Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning immigration_data \n",
      "appending ... \n",
      "written out parquet file parquet_files/immigration_data.parquet , time taken in seconds = 67.22 \n",
      "immigration data appended \n"
     ]
    }
   ],
   "source": [
    "# Step 1:  Read in new immigration the data here\n",
    "immigration_data =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat')\n",
    "\n",
    "# Step 2: Clean Data \n",
    "immigration_data = clean_data_source(immigration_data,\"immigration_data\")\n",
    "\n",
    "# Step 3: update  / append parquet file\n",
    "writeParquet(immigration_data,\"immigration_data\",\"parquet_files/\",0)\n",
    "\n",
    "print(\"immigration data appended \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.3 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immigration_data \t rows=6830099 \t calculation time =0.56 s \t Parquet file=parquet_files/immigration_data.parquet \n",
      "countryCodes \t rows=289 \t calculation time =0.31 s \t Parquet file=parquet_files/countryCodes.parquet \n",
      "us_ports \t rows=591 \t calculation time =0.30 s \t Parquet file=parquet_files/us_ports.parquet \n",
      "airlineCodes \t rows=1525 \t calculation time =0.36 s \t Parquet file=parquet_files/airlineCodes.parquet \n",
      "us_state_cities \t rows=596 \t calculation time =0.40 s \t Parquet file=parquet_files/us_state_cities.parquet \n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "# The first check we will do is read in the parquet files and make sure all have data inside\n",
    "# We will define a function that can be applied to all data sources. \n",
    "def check_data_rows(sourceName,parquet_storageSource):\n",
    "    \"\"\"\n",
    "        function check_data_rows\n",
    "            input = sourcename :: Type = String --> variable that defines name of parquet file and also process to write out (e.g. partition by etc).                 \n",
    "    \"\"\"\n",
    "    try:\n",
    "#        parquet_storageSource = \"parquet_files/\"  \n",
    "        filename = parquet_storageSource + sourceName + \".parquet\"\n",
    "\n",
    "        # time flag to keep track of how long it takes to write the file. \n",
    "        start = time.time()\n",
    "\n",
    "        # Check if parquet file exists\n",
    "        if not os.path.exists(filename):\n",
    "            print(\"Parquet file {} not found\".format(filename))\n",
    "            sys.exit(1)\n",
    "\n",
    "        # read in the parquet file if the first test is passed. \n",
    "        parquetFile = spark.read.parquet(filename)\n",
    "\n",
    "        # Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "        parquetFile.createOrReplaceTempView(sourceName)\n",
    "        # create sql command\n",
    "        sql_command = \" select count(1) as n_rows from {} \".format(sourceName)\n",
    "        # execute sql\n",
    "        result = spark.sql(sql_command)\n",
    "        # get result for n_rows\n",
    "        rows = result.collect()[0]['n_rows']\n",
    "        \n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"{} \\t rows={} \\t calculation time ={:.2f} s \\t Parquet file={} \".format(sourceName,rows,(end-start),filename ) )\n",
    "    except BaseException as e:\n",
    "        print(\"Exception occured during reading parquet file -- ERROR = {}\".format(e))\n",
    "        \n",
    "# Execute the procedure for all data sources\n",
    "parquet_storageSource = \"parquet_files/\"\n",
    "check_data_rows(\"immigration_data\",parquet_storageSource)\n",
    "check_data_rows(\"countryCodes\",parquet_storageSource)\n",
    "check_data_rows(\"us_ports\",parquet_storageSource)\n",
    "check_data_rows(\"airlineCodes\",parquet_storageSource)\n",
    "check_data_rows(\"us_state_cities\",parquet_storageSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning us_state_cities \n",
      "An exception occurred, invalid data format given for source us_state_cities -- ERROR = drop() got an unexpected keyword argument 'columns' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### FUNCTIONALITY TESTS\n",
    "# The second test would be to run the invidual functions with wrong input data (e.g. wrong source name, wrong data format)\n",
    "# First we will try to clean data with wrong source name\n",
    "immigration_data = clean_data_source(immigration_data,\"us_state_cities\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Unknown, pipleline not programmed to write parquet for us_states \n",
      "Exception occured during writing parquet file -- ERROR = 1\n",
      "\n",
      "cleaning us_states \n",
      "Source Unknown, pipleline not programmed to clean us_states \n",
      "An exception occurred, invalid data format given for source us_states -- ERROR = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next we will try to execute both our cleaning and writing functions for a source that isnt programmed / defined\n",
    "us_ct_demogr = writeParquet(immigration_data,\"us_states\",1)\n",
    "immigration_data = clean_data_source(immigration_data,\"us_states\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "<br> A data dictionary is created under file/data_dictionary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head>\n",
       "<title>Schema Report for database: mydb</title>\n",
       "<style>\n",
       "        td,th {\n",
       "        text-align:left;\n",
       "        vertical-align:middle;\n",
       "        }\n",
       "        table {\n",
       "        border-collapse: collapse;\n",
       "        border: 1px solid;\n",
       "        }\n",
       "        caption, th, td {\n",
       "        padding: .2em .8em;\n",
       "        border: 1px solid #000000;\n",
       "        }\n",
       "        caption {\n",
       "        background: #D3D3D3;\n",
       "        font-weight: bold;\n",
       "        font-size: 1.1em;\n",
       "        }\n",
       "        th {\n",
       "        font-weight: bold;\n",
       "        background: #000000;\n",
       "        color: white;\n",
       "        }\n",
       "        td {\n",
       "        background: #FFFFFF;\n",
       "        }\n",
       "        </style>\n",
       "      </head>\n",
       "     <body>\n",
       "<h1>Schema Report for database: mydb</h1>\n",
       "<a id=\"home\">Table List </a><br /><ul>\n",
       "<li><a href=\"#countryCodes\">countryCodes </a></li>\n",
       "<li><a href=\"#us_state_cities\">us_state_cities </a></li>\n",
       "<li><a href=\"#us_ports\">us_ports </a></li>\n",
       "<li><a href=\"#airlineCodes\">airlineCodes </a></li>\n",
       "<li><a href=\"#immigration_data\">immigration_data </a></li>\n",
       "</ul>\n",
       "<a id=\"countryCodes\"></a><table style=\"width:100%\"><caption>Table: countryCodes </caption>\n",
       "<tr><td>Table Comments</td><td colspan=\"6\"></td></tr>\n",
       "<tr><td colspan=\"7\">Columns</td></tr>\n",
       "        <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Data Type</th>\n",
       "        <th>Nullable</th>\n",
       "        <th>PK</th>\n",
       "        <th>FK</th>\n",
       "        <th>Default</th>\n",
       "        <th>Comment</th>\n",
       "        </tr>\n",
       "<tr><td>countryCode</td><td>INT</td><td>Yes</td><td>Yes</td><td>No</td><td></td><td>Unique numeric country code for the country</td></tr>\n",
       "<tr><td>countryName</td><td>VARCHAR(45)</td><td>No</td><td>No</td><td>No</td><td></td><td>Name of the country</td></tr>\n",
       "</table><a href=\"#home\">Table List </a></br>\n",
       "<a id=\"us_state_cities\"></a><table style=\"width:100%\"><caption>Table: us_state_cities </caption>\n",
       "<tr><td>Table Comments</td><td colspan=\"6\"></td></tr>\n",
       "<tr><td colspan=\"7\">Columns</td></tr>\n",
       "        <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Data Type</th>\n",
       "        <th>Nullable</th>\n",
       "        <th>PK</th>\n",
       "        <th>FK</th>\n",
       "        <th>Default</th>\n",
       "        <th>Comment</th>\n",
       "        </tr>\n",
       "<tr><td>stateCode</td><td>VARCHAR(5)</td><td>Yes</td><td>No</td><td>No</td><td></td><td>State code for the State (e.g. CA = California)</td></tr>\n",
       "<tr><td>stateName</td><td>VARCHAR(45)</td><td>Yes</td><td>No</td><td>No</td><td></td><td>Name of State</td></tr>\n",
       "<tr><td>cityName</td><td>VARCHAR(45)</td><td>Yes</td><td>No</td><td>No</td><td></td><td>Name of City</td></tr>\n",
       "</table><a href=\"#home\">Table List </a></br>\n",
       "<a id=\"us_ports\"></a><table style=\"width:100%\"><caption>Table: us_ports </caption>\n",
       "<tr><td>Table Comments</td><td colspan=\"6\"></td></tr>\n",
       "<tr><td colspan=\"7\">Columns</td></tr>\n",
       "        <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Data Type</th>\n",
       "        <th>Nullable</th>\n",
       "        <th>PK</th>\n",
       "        <th>FK</th>\n",
       "        <th>Default</th>\n",
       "        <th>Comment</th>\n",
       "        </tr>\n",
       "<tr><td>portCode</td><td>VARCHAR(5)</td><td>Yes</td><td>No</td><td>No</td><td></td><td>Unique port code which identifies the port of immigration</td></tr>\n",
       "<tr><td>stateCode</td><td>VARCHAR(5)</td><td>Yes</td><td>No</td><td>Yes</td><td></td><td>State code where the port resides. Extracted from source. </td></tr>\n",
       "<tr><td>portName</td><td>VARCHAR(80)</td><td>No</td><td>No</td><td>No</td><td></td><td>Name of port</td></tr>\n",
       "</table><a href=\"#home\">Table List </a></br>\n",
       "<a id=\"airlineCodes\"></a><table style=\"width:100%\"><caption>Table: airlineCodes </caption>\n",
       "<tr><td>Table Comments</td><td colspan=\"6\"></td></tr>\n",
       "<tr><td colspan=\"7\">Columns</td></tr>\n",
       "        <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Data Type</th>\n",
       "        <th>Nullable</th>\n",
       "        <th>PK</th>\n",
       "        <th>FK</th>\n",
       "        <th>Default</th>\n",
       "        <th>Comment</th>\n",
       "        </tr>\n",
       "<tr><td>airlineID</td><td>INT</td><td>Yes</td><td>Yes</td><td>No</td><td></td><td>Unique ID for each airline, extracted from airline database. </td></tr>\n",
       "<tr><td>airlineName</td><td>VARCHAR(100)</td><td>No</td><td>No</td><td>No</td><td></td><td>Name of the airline</td></tr>\n",
       "<tr><td>airline_iata_code</td><td>VARCHAR(10)</td><td>Yes</td><td>No</td><td>No</td><td></td><td>the international iata code for the airline</td></tr>\n",
       "<tr><td>airlineCountry</td><td>VARCHAR(50)</td><td>No</td><td>No</td><td>No</td><td></td><td>Airline's home country</td></tr>\n",
       "</table><a href=\"#home\">Table List </a></br>\n",
       "<a id=\"immigration_data\"></a><table style=\"width:100%\"><caption>Table: immigration_data </caption>\n",
       "<tr><td>Table Comments</td><td colspan=\"6\"></td></tr>\n",
       "<tr><td colspan=\"7\">Columns</td></tr>\n",
       "        <tr>\n",
       "        <th>Name</th>\n",
       "        <th>Data Type</th>\n",
       "        <th>Nullable</th>\n",
       "        <th>PK</th>\n",
       "        <th>FK</th>\n",
       "        <th>Default</th>\n",
       "        <th>Comment</th>\n",
       "        </tr>\n",
       "<tr><td>year</td><td>INT</td><td>No</td><td>No</td><td>No</td><td></td><td>Year which immigration data refers to. </td></tr>\n",
       "<tr><td>month</td><td>INT</td><td>No</td><td>No</td><td>No</td><td></td><td>Month which immigration data refers to. </td></tr>\n",
       "<tr><td>cit</td><td>INT</td><td>No</td><td>No</td><td>Yes</td><td></td><td>Country code which identifies the country of travel for the immigrant.</td></tr>\n",
       "<tr><td>res</td><td>INT</td><td>No</td><td>No</td><td>Yes</td><td></td><td>Country code which identifies the residence country for the immigrant. </td></tr>\n",
       "<tr><td>portCode</td><td>VARCHAR(5)</td><td>No</td><td>No</td><td>Yes</td><td></td><td>Port code referring to the port of arrival</td></tr>\n",
       "<tr><td>arrivalDate</td><td>DATE</td><td>No</td><td>No</td><td>No</td><td></td><td>arrival date of the immigrant</td></tr>\n",
       "<tr><td>mode</td><td>VARCHAR(50)</td><td>No</td><td>No</td><td>No</td><td></td><td>mode of transport. The viable options are 1 = 'Air', 2 = 'Sea', 3 = 'Land', 9 = 'Not reported'</td></tr>\n",
       "<tr><td>depDate</td><td>DATE</td><td>No</td><td>No</td><td>No</td><td></td><td>departure date of immigrant</td></tr>\n",
       "<tr><td>age</td><td>INT</td><td>No</td><td>No</td><td>No</td><td></td><td>age of immigrant</td></tr>\n",
       "<tr><td>visaType</td><td>VARCHAR(50)</td><td>No</td><td>No</td><td>No</td><td></td><td>Type of visa that was issued, the options are Business, Pleasure, Student</td></tr>\n",
       "<tr><td>matchFlag</td><td>VARCHAR(10)</td><td>No</td><td>No</td><td>No</td><td></td><td>Match flag when set indicates a match of arrival and departure records</td></tr>\n",
       "<tr><td>gender</td><td>VARCHAR(5)</td><td>No</td><td>No</td><td>No</td><td></td><td>immigrant gender</td></tr>\n",
       "<tr><td>airlineCode</td><td>VARCHAR(10)</td><td>No</td><td>No</td><td>Yes</td><td></td><td>airline code which indicates the airline through which the immigrant arrived</td></tr>\n",
       "<tr><td>flightNumber</td><td>VARCHAR(10)</td><td>No</td><td>No</td><td>No</td><td></td><td>Flight number of Airline used to arrive in U.S. </td></tr>\n",
       "<tr><td>visaCat</td><td>VARCHAR(10)</td><td>No</td><td>No</td><td>No</td><td></td><td>Class of admission legally admitting the non-immigrant to temporarily stay in U.S. e.g. B1, F1</td></tr>\n",
       "</table><a href=\"#home\">Table List </a></br>\n",
       "</body></html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename='files/data_dictionary.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.4 Analytic Query examples \n",
    "Below is a demostration of how the parquet files can be read in and the data-model be queried\n",
    "<br>\n",
    "A few example queries are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|     portName|n_of_immigrants|\n",
      "+-------------+---------------+\n",
      "|     NEW YORK|         485916|\n",
      "|        MIAMI|         343941|\n",
      "|  LOS ANGELES|         310163|\n",
      "|SAN FRANCISCO|         152586|\n",
      "|      ORLANDO|         149195|\n",
      "+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Query took 3.221921682357788 s\n"
     ]
    }
   ],
   "source": [
    "# Query 1: Which where the top 5 busiest ports in month 04 / 2016\n",
    "# We will read in two data sets, 1- Immigration data, 2- us_ports\n",
    "\n",
    "immigration_data = spark.read.parquet(\"parquet_files/immigration_data.parquet\")\n",
    "us_ports = spark.read.parquet(\"parquet_files/us_ports.parquet\")\n",
    "\n",
    "# time flag to keep track of how long it takes to write the file. \n",
    "start = time.time()\n",
    "\n",
    "# Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "immigration_data.createOrReplaceTempView(\"immigration_data\")\n",
    "us_ports.createOrReplaceTempView(\"us_ports\")\n",
    "\n",
    "# create sql command\n",
    "sql_command = (\"\"\" \n",
    "        select p.portName,count(1) as n_of_immigrants  \n",
    "        from immigration_data i join us_ports p on i.portCode = p.portCode\n",
    "        where i.year=2016\n",
    "        and i.month = 4\n",
    "        group by i.year,i.month,p.portCode,p.portName\n",
    "        order by count(1) desc\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# execute sql\n",
    "result = spark.sql(sql_command)\n",
    "\n",
    "# show the top 5 results\n",
    "result.show(n=5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Query took {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------+\n",
      "|year|month|n_of_immigrants|\n",
      "+----+-----+---------------+\n",
      "|2016|    9|        3733786|\n",
      "|2016|    4|        3096313|\n",
      "+----+-----+---------------+\n",
      "\n",
      "Query took 1.2313463687896729 s\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Which months have the highest immigration inflow\n",
    "# since we have loaded only 2 months of data, the query will list the months and their counts descending\n",
    "\n",
    "# We will read in just Immigration data\n",
    "immigration_data = spark.read.parquet(\"parquet_files/immigration_data.parquet\")\n",
    "\n",
    "# time flag to keep track of how long it takes to write the file. \n",
    "start = time.time()\n",
    "\n",
    "# Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "immigration_data.createOrReplaceTempView(\"immigration_data\")\n",
    "\n",
    "# create sql command\n",
    "sql_command = (\"\"\" \n",
    "        select i.year,i.month,count(1) as n_of_immigrants  \n",
    "        from immigration_data i \n",
    "        group by i.year,i.month\n",
    "        order by count(1) desc\n",
    "\"\"\")\n",
    "\n",
    "# execute sql\n",
    "result = spark.sql(sql_command)\n",
    "\n",
    "# show the top 5 results\n",
    "result.show(n=5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Query took {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------+---------------+\n",
      "| stateName|        portName|visaType|n_of_immigrants|\n",
      "+----------+----------------+--------+---------------+\n",
      "|California|     LOS ANGELES|Pleasure|       87425728|\n",
      "|California|   SAN FRANCISCO|Pleasure|       40026331|\n",
      "|   Florida|           MIAMI|Pleasure|       31660752|\n",
      "|California|     LOS ANGELES|Business|       14349928|\n",
      "|   Florida|         ORLANDO|Pleasure|       12747408|\n",
      "|California|   SAN FRANCISCO|Business|       12345070|\n",
      "|  New York|        NEW YORK|Pleasure|       10523700|\n",
      "|     Texas|         HOUSTON|Pleasure|        8995170|\n",
      "|   Florida| FORT LAUDERDALE|Pleasure|        7545744|\n",
      "|     Texas|          DALLAS|Pleasure|        6371631|\n",
      "|California|     LOS ANGELES| Student|        4056159|\n",
      "|  Illinois|         CHICAGO|Pleasure|        3800684|\n",
      "|     Texas|         HOUSTON|Business|        3019917|\n",
      "|   Florida|           MIAMI|Business|        2978256|\n",
      "|New Jersey|NEWARK/TETERBORO|Pleasure|        2889780|\n",
      "+----------+----------------+--------+---------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "Query took 88.79775166511536 s\n"
     ]
    }
   ],
   "source": [
    "# Query 3 : Which US Port/States have the highest number of immigrants, what is their visa type (i.e. Student, Business, Pleasure)\n",
    "\n",
    "# We will read in three data sets, 1- Immigration data, 2- us_ports, 3- us_state_cities\n",
    "\n",
    "immigration_data = spark.read.parquet(\"parquet_files/immigration_data.parquet\")\n",
    "us_ports = spark.read.parquet(\"parquet_files/us_ports.parquet\")\n",
    "us_state_cities = spark.read.parquet(\"parquet_files/us_state_cities.parquet\")\n",
    "\n",
    "# time flag to keep track of how long it takes to write the file. \n",
    "start = time.time()\n",
    "\n",
    "# Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "immigration_data.createOrReplaceTempView(\"immigration_data\")\n",
    "us_ports.createOrReplaceTempView(\"us_ports\")\n",
    "us_state_cities.createOrReplaceTempView(\"us_state_cities\")\n",
    "\n",
    "# create sql command\n",
    "sql_command = (\"\"\" \n",
    "        select s.stateName,p.portName,i.visaType, count(1) as n_of_immigrants  \n",
    "        from immigration_data i join us_ports p on i.portCode = p.portCode\n",
    "                                join us_state_cities s on p.stateCode = s.stateCode\n",
    "        group by s.stateName,p.portName,i.visaType\n",
    "        order by count(1) desc\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# execute sql\n",
    "result = spark.sql(sql_command)\n",
    "\n",
    "# show the top 5 results\n",
    "#result.orderBy('n_of_immigrants',ascending=False).show(n=15)\n",
    "result.show(n=15)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Query took {} s\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+---------------+\n",
      "|         airlineName|   airlineCountry|n_of_immigrants|\n",
      "+--------------------+-----------------+---------------+\n",
      "|   American Airlines|    United States|         656844|\n",
      "|     United Airlines|    United States|         601940|\n",
      "|     Delta Air Lines|    United States|         554346|\n",
      "|     British Airways|   United Kingdom|         386662|\n",
      "|     Lufthansa Cargo|          Germany|         253547|\n",
      "|           Lufthansa|          Germany|         253547|\n",
      "|Virgin Atlantic A...|   United Kingdom|         233030|\n",
      "|          Korean Air|Republic of Korea|         160031|\n",
      "|          Air France|           France|         152751|\n",
      "|      Japan Airlines|            Japan|         150572|\n",
      "+--------------------+-----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Query took 5.1944944858551025 s\n"
     ]
    }
   ],
   "source": [
    "# Query 4 : which airline has the maximum number of passengers\n",
    "# We will read in two data sets, 1- Immigration data, 2- airlineCodes\n",
    "\n",
    "immigration_data = spark.read.parquet(\"parquet_files/immigration_data.parquet\")\n",
    "airlineCodes = spark.read.parquet(\"parquet_files/airlineCodes.parquet\")\n",
    "\n",
    "# time flag to keep track of how long it takes to write the file. \n",
    "start = time.time()\n",
    "\n",
    "# Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "immigration_data.createOrReplaceTempView(\"immigration_data\")\n",
    "airlineCodes.createOrReplaceTempView(\"airlineCodes\")\n",
    "\n",
    "# create sql command\n",
    "sql_command = (\"\"\" \n",
    "        select a.airlineName,a.airlineCountry,count(1) as n_of_immigrants  \n",
    "        from immigration_data i join airlineCodes a on i.airlineCode = a.airline_iata_code\n",
    "        group by a.airlineName,a.airlineCountry\n",
    "        order by count(1) desc\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# execute sql\n",
    "result = spark.sql(sql_command)\n",
    "\n",
    "result.show(n=10)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Query took {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|         countryName|n_of_immigrants|\n",
      "+--------------------+---------------+\n",
      "|          CHINA, PRC|          61819|\n",
      "|               INDIA|          13984|\n",
      "|         SOUTH KOREA|          11726|\n",
      "|        SAUDI ARABIA|           7708|\n",
      "|               JAPAN|           7558|\n",
      "|              TAIWAN|           5101|\n",
      "|              BRAZIL|           4317|\n",
      "|  MEXICO Air Sea,...|           4105|\n",
      "|             VIETNAM|           2915|\n",
      "|              FRANCE|           2779|\n",
      "+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Query took 2.113755941390991 s\n"
     ]
    }
   ],
   "source": [
    "# Query 5 : Which residence country has the highest number of students\n",
    "# We will read in two data sets, 1- Immigration data, 2- country Codes\n",
    "\n",
    "immigration_data = spark.read.parquet(\"parquet_files/immigration_data.parquet\")\n",
    "countryCodes = spark.read.parquet(\"parquet_files/countryCodes.parquet\")\n",
    "\n",
    "# time flag to keep track of how long it takes to write the file. \n",
    "start = time.time()\n",
    "\n",
    "# Parquet files can also be used to create a temporary view and then used in SQL statements.       \n",
    "immigration_data.createOrReplaceTempView(\"immigration_data\")\n",
    "countryCodes.createOrReplaceTempView(\"countryCodes\")\n",
    "\n",
    "# create sql command\n",
    "sql_command = (\"\"\" \n",
    "        select c.countryName,count(1) as n_of_immigrants  \n",
    "        from immigration_data i join countryCodes c on i.res = c.countryCode\n",
    "        where visaType='Student'\n",
    "        group by c.countryName\n",
    "        order by count(1) desc\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# execute sql\n",
    "result = spark.sql(sql_command)\n",
    "\n",
    "result.show(n=10)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Query took {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nature of data and the requirement of continues updates to data, spark framework for processing along with parquet file as storage was chosen \n",
    "<br> Core of our model will be the immigration data set. Which itself is huge, millions of rows of data every month. \n",
    "<br> To process this **big** data efficiently, we will use spark as our framework. \n",
    "<br> Spark has various libraries and features built in e.g. Spark SQL which gives a very neat way to query and extract information from spark data frames.\n",
    "Spark dataframes work best with parquet files, so it will be used to create our data lake. \n",
    "There are various advantages for choosing parquet files :\n",
    "   1. They are much more storage efficient than normal csv / delimited files\n",
    "   2. Columnar based storage, so we will limit the amount of IO based on our query (only columns involved in query are read)\n",
    "   3. It can be directly read into Spark dataframe, and the schema is preserved.\n",
    "   4. It is easy to increment / write out partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immigration data is updated every second, since we are creating a data lake for historical analysis it is recommended to update the immigration every month\n",
    "<br> CountryCodes , PortCodes will rarely be updated as its not everyday that a new country or a new state is made. Hence this part of data will remain pretty static\n",
    "<br> Airlines comparatively updated frequently (e.g new airline introduced, an old airline closed, airline iata code is update and so on). It is recommended that along with immigration_data, this data should also be updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the data is imported and analysis run as a simulation for what can be achieved. \n",
    "<br> **if this data was to increase by 100x**, A couple of options can be tested to process it more efficiently\n",
    "1. Build a pipeline that can be run in parallel. Since the steps of etl are fairly broken down, it will be simple to integrate them within Airflow and run them in parallel to speed up the loading / cleaning and writing of data. \n",
    "1. Increasing the number of spark cluster nodes\n",
    "2. Defining a different partitioning pattern\n",
    "3. Working with a hybrid model (i.e. distributed accross a database and data lakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the data pipeine needs to be run every-day** \n",
    "<br> Airflow will again be a good choice to load the data regularly in parallel without intervention. \n",
    "<br> depending on the dashboard needs static cached data views (similar to database mateliazed views) can be created for every 24Hrs. So everyday before 7am, a procedure can run that can create a view for the remaining 24Hrs only and can be cached. \n",
    "<br> benefit of caching would be that there will be no need to reprocess / re-read all data. Instead only the *incremental* processing is done which would be much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if data needs to be access by 100+ people**\n",
    "<br>An option to explore will be data replication and load balancing factors accross spark cluster.\n",
    "1. Data will be partitioned and distributed so each server has to process its own data only\n",
    "2. Data will be replicated so Person X's query can be answered by Server A where as the same query by Person Y can be answered by Server B. This will even out load accross the servers\n",
    "3. If the peoeple are geo-graphically distributed, we can also distributed the data geo-graphically so that the region's data stays local\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
